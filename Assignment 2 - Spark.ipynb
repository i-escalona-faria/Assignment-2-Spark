{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Learning_Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_rdd = sc.textFile('Users.xml').persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_rdd.filter(lambda item: '<row Id=\"' in item).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_rdd.filter(lambda item: '<row Id=\"' in item).map(lambda item: item[7:(len(item)-3)].encode('utf-8')).map(lambda item2: str(item2).replace( '\\\" ','=\\\"').split('=\\\"')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = users_rdd.filter(lambda item: '<row Id=\"' in item).map(lambda item: item[7:(len(item)-3)].encode('utf-8')).map(lambda item2: str(item2).replace( '\\\" ','=\\\"').split('=\\\"')).map(lambda t: list(map(lambda v,w : (v,w), filter(lambda u : t.index(u) % 2 == 0, t), filter(lambda u : t.index(u) % 2 == 1, t)))).persist()\n",
    "question1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "#### From the Users.xml file, find all users which are from Georgia and output to screen their DisplayName only. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_result = question1.map(lambda sub_list: list(filter(lambda item: item[0] == 'Id' or item[0] == 'Location' or item[0] == 'DisplayName',sub_list))).filter(lambda sublist: len(sublist) == 3).filter(lambda sub_list: 'GA' in sub_list[2][1] or 'georgia' in sub_list[2][1].lower()).map(lambda sub_list: sub_list[1][1]).collect()\n",
    "print(question1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "#### Using the Users.xml file, provide the count for all users which joined (CreationDate) in 2017. (30 points). Output this to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2_result = question2.filter(lambda sub_list: filter(lambda item: item[0] == 'CreationDate' and '2017' in item[1],sub_list)).count()\n",
    "print(question2_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "#### Using the PostHistory file, count the number of Posts that feature the words “Spark” and “Scala”. Output this to the screen. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = sc.textFile('PostHistory.xml').filter(lambda item: '<row Id=\"' in item).map(lambda item: item[7:(len(item)-3)].encode('utf-8')).filter(lambda item: 'scala ' in item.lower() or 'scala. ' in item or 'scala,' in item.lower() or 'scala;' in item.lower() or 'scala\\'' in item.lower() or 'pyspark' in item.lower()).count()\n",
    "print(question3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "#### Using the PostHistory file, provide a total count of the words used by each distinct user. In other words, count all words in all posts for each user and display this to screen. You can only identify users by the UserID (30 points). You get 15 bonus points if you get the actual DisplayName of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_rdd = sc.textFile('PostHistory.xml').filter(lambda item: '<row Id=\"' in item).map(lambda item: item[7:len(item)-3].encode('utf-8').replace('\\\" ', '=\\\"').split('=\\\"')).map(lambda t: list(map(lambda v,w : (v,w), filter(lambda u : t.index(u) % 2 == 0, t), filter(lambda u : t.index(u) % 2 == 1, t)))).map(lambda sub_list: filter(lambda item: item[0] == 'Id' or item[0] == 'Text', sub_list)).filter(lambda item: len(item) == 2).map(lambda sub_list: (sub_list[0][1],sub_list[1][1])).reduceByKey(lambda x,y: str(x)+str(y)).map(lambda item: (item[0],len(item[1].split(\" \"))))\n",
    "post_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".map(lambda sub_list: filter(lambda item: item == 'Id' or item == 'Text',sub_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
